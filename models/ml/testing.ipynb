{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "extra_stop_words = {\"href\", \"com\", \"ii\", \"iii\", \"ie\", \"quot\"}\n",
    "stop_words = set(stopwords.words('english')).union(extra_stop_words)\n",
    "\n",
    "def preprocess_text_for_bert_with_source_removal(text, is_description=False):\n",
    "    # Remove HTML-like tags and special codes (e.g., &lt;b&gt;)\n",
    "    text = re.sub(r'&lt;[^&]+&gt;', '', text)\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove source information\n",
    "    if is_description:\n",
    "        # Remove source at the beginning in descriptions (e.g., \"Source - Description\")\n",
    "        text = re.sub(r'^\\w+\\s-\\s', '', text)\n",
    "    else:\n",
    "        # Remove source in parentheses at the end of titles\n",
    "        text = re.sub(r'\\s\\([^)]*\\)$', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize and remove stop words\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preproces_on_test(text):\n",
    "    #text = preprocess_text_for_bert_with_source_removal(text)\n",
    "    text = preprocess_text_for_bert_with_source_removal(text, is_description=True)\n",
    "    tokenized = word_tokenize(text)\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stemmed = [porter_stemmer.stem(word) for word in tokenized]\n",
    "    sentence = \" \".join(stemmed)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "path = \"/Users/basakdemirok/Desktop/2025 GUZ/ELE 513 ANN/PROJE/ELE513/model_saved/\"\n",
    "# Load the models\n",
    "xgb_model_tf_idf = joblib.load(path + 'xgb_model_tf_idf.joblib')\n",
    "rf_model_tfidf = joblib.load(path + 'rf_model_tf_idf.joblib')\n",
    "knn_model_tfidf = joblib.load(path + 'knn_model_tf_idf.joblib')\n",
    "vectorizer = joblib.load(path + 'tf_idf_vectorizer_fitted.joblib')\n",
    "\n",
    "\n",
    "svm_model_tfidf = joblib.load(path + 'svm_model_tf_idf.joblib')\n",
    "mnb_model_tfidf = joblib.load(path + 'mnb_model_tf_idf.joblib')\n",
    "lr_model_tfidf = joblib.load(path + 'logistic_model_tf_idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"this news is about the world. In the World War 2, Germany did not wim the war.\"\n",
    "test_text_sport = \"Latest sport news includes American football, basketball, tennis, and soccer.\"\n",
    "test_test_business = \"The CEO of the XYZ company has just announced that they prepared a new product for the market. Also, CFO of the company will be replaced by the new CFO\"\n",
    "test_text_science = \"The latest scientific news includes the discovery of a new element, the study of the effects of climate change, and the development of a new vaccine.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = preproces_on_test(test_text)\n",
    "processed_text_sport = preproces_on_test(test_text_sport)\n",
    "processed_text_business = preproces_on_test(test_test_business)\n",
    "processed_text_science = preproces_on_test(test_text_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized = vectorizer.transform([processed_text])\n",
    "vectorized_sport = vectorizer.transform([processed_text_sport])\n",
    "vectorized_business = vectorizer.transform([processed_text_business])\n",
    "vectorized_science = vectorizer.transform([processed_text_science])\n",
    "\n",
    "vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(lr_model_tfidf.predict(vectorized))\n",
    "print(lr_model_tfidf.predict(vectorized_sport))\n",
    "print(lr_model_tfidf.predict(vectorized_business))\n",
    "print(lr_model_tfidf.predict(vectorized_science))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
